## 使用BPANN做一个实验——手写数字识别

这一章我们将做一个实验，使用我们前面写的BPANN的代码来实现手写数字识别的效果。手写数字识别应该是很多的神经网络的入门案例，正好，我也刚入门，我们在这一章当中将会使用到一个手写数字的数据库——MNIST，我已经下载好了，到时候你直接`git clone ···`，当然，我自己也有自己保存的一些手写数字的图片，自己做过测试，但是我不准备在这里贴出相关的代码了，因为有一些涉及到别的知识的地方，不好解释，干脆我就不解释，使用MNIST的吧。

另外我在这个实验中使用到了opencv，如果你想在自己的机子上运行我的代码的话，那你应该安装上opencv，当然，你也可以使用别的图像处理的包，只不过你需要自己写一下代码。

首先介绍一下，MNIST里面的数据是图片与标签是分成两个文件，其中文件名为`train-images.idx3-ubyte`表示保存图片的文件，这个文件包含60000个图片，每一张图片都是灰度图像，并且MNIST已经将其平铺了。比如说每一张图片的尺寸是28*28，那么它平铺下来的数据就是28*28 = 784，需要784个数来表示这整个一张图片，每一个数都是0~255之间的灰度值，如果我们想要显示这张图片，只需要取到这784个灰度值然后将其转变成28*28的灰度图像即可。另外一个文件就是`train-labels.idx1-ubyte`，这个文件存放的是每一张图片的标签，标签就是0~9之间的数，它与前者是相对应的，如果前者（包含图片的文件）所存储的图片是1，那么这个文件下对应的数字就是1，其他的类似。


我们要使用MNIST里面的数据，就得先提取出来不是，下面我们来看一下提取的程序是什么样的，这些文件是通过字节来存储的，所以我们也要通过字节来获取，首先我们得引入`struct`这个包，这个包是Python内置的。


```bash
#MNISTtrain.py

import struct
import numpy

import BPANN

def getDataFromFile(  imagePath, labelPath, samples = 1000, func=None ):
    """
        从MNIST数据集中获取数据，因为在新的MNIST数据集中，数据存放的方式是将每一个图片铺平之后序列存储到文件中的，所以我们可以反过来将其读取出来。
        inputs:
	        imagePath : 保存图片的文件
	        labelPath : 保存图像标签信息的文件
	        samples : 需要取得多少的图片，默认为1000张
	        func : 在获取每一张图片之前是否需要处理一下，比如细化，或者我们想获取的是图像的其他信息，可以由这个函数来处理
    """
    binaryImageData = open( imagePath, 'rb' )
    imageBuffer = binaryImageData.read()
    binaryImageData.close()
    
    binaryLabel = open( labelPath , 'rb' )
    labelBuffer = binaryLabel.read()
    binaryLabel.close()
    
    trainData = []
    resultData = []
    #使用大端法读取四个整型数---每个整型数4个字节，分别为魔数、图片数量、图片像素行列数，
    #index为位置指针。(魔数，图片类型的数)
    #不过我们不需要这些东西
    index = 0
    #magic, numImages, numRows, numColums=struct.unpack_from('>iiii', imageBuffer, index )
    
    index += struct.calcsize('>iiii' )
    
    for x in range(samples):
        img = numpy.array( struct.unpack_from( '>784B', imageBuffer, index ) )\
                    .reshape( 28, 28).astype( numpy.uint8 )
        #二值化图像
        img[numpy.where( img[:, :] > 0)] = 1
        
        if func is None:
            img = img.reshape( 784, -1 )
        else:
            img = func( img )

        trainData.append( img )
        index += struct.calcsize( '>784B' )
    
    #获得对应的标签
    index = struct.calcsize('>ii' )
    for x in range(samples):
        r = numpy.zeros( 10 ).reshape( 10, -1 )
        result = numpy.array( struct.unpack_from( '>B', labelBuffer, index ) )[0]
        r[result] = 1;
        resultData.append( r )
        index += struct.calcsize( '>B' )
        
    return zip( trainData, resultData )
```

我们来看一看我们获取的MNIST的数字与其相应的标签是什么样的，这一部分我就直接写在MNISTtrain.py文件之中了，我使用到了opencv。

```bash

	def imshow( img, nameOfWindow='nameOfWindow' ):
		cv2.imshow( nameOfWindow, img )
		cv2.waitKey(0)
		cv2.destroyAllWindows()

	
	"""
	将灰度图像转换成彩色图像，方便查看效果
	"""
	def cvt2BGR( img ):
		edges = cv2.cvtColor( img.copy(), cv2.COLOR_GRAY2BGR )
		return edges

	train = getDataFromFile( './samples/train-images.idx3-ubyte', './samples/	train-labels.idx1-ubyte', 60000 )

    for i in range( 10 ):
        img = train[i][0].reshape( 28, 28 ).astype( numpy.uint8 ) * 255 
        number = numpy.argmax( train[i][1] )
        font = cv2.FONT_HERSHEY_SIMPLEX
        img = cvt2BGR( img )
        cv2.putText( img, str( number ), ( 0, 20 ), font, 1, ( 255, 0, 0 ), 1 )
        imshow( img )

```

上面这些代码会显示10张图片，以及在图片上会写上它们的各自的标签。这些部分的代码知识为了证明我们获取的图片是没有出现什么错误的，当我们要训练神经网络的时候，最好把它注释掉。

#### 训练神经网络

现在数据也准备好了，我们可以开始训练我们的网络了。我们的图片的像素点是784个，所以我们的输入层的神经元的数量应该是784个，隐藏层的不确定，那么我们就设置它为30吧，输出层是10个，因为数字只有10个。

```bash
    # 初始化神经网络
    net = BPANN.BPANN( [784, 30, 10 ] )
    
    # 训练，参数比较随意，所以结果不是最佳的
    #30表示迭代次数
    #6表示我们将训练的数据分成若干份，每一份包含6个数据
    #0.2表示学习速率
    net.SGD( train[:50000], 30, 6, 0.2, train[50000:] )
    
    # 保存网络的参数
    net.save( 'netParam.txt' )
```

我自己运行了一下程序，结果如下：
```bash
Epoch 0 training complete
The accuracy of test data is 8853 / 10000 
Epoch 1 training complete
The accuracy of test data is 8952 / 10000 
Epoch 2 training complete
The accuracy of test data is 9149 / 10000 
Epoch 3 training complete
The accuracy of test data is 9231 / 10000 
Epoch 4 training complete
The accuracy of test data is 9188 / 10000 
Epoch 5 training complete
The accuracy of test data is 9253 / 10000 
Epoch 6 training complete
The accuracy of test data is 9262 / 10000 
Epoch 7 training complete
The accuracy of test data is 9256 / 10000 
Epoch 8 training complete
The accuracy of test data is 9333 / 10000 
Epoch 9 training complete
The accuracy of test data is 9300 / 10000 
```

当然你的程序运行结果跟我的一定会有所差别，因为我们的权值与阈值是随机赋值的，所以不可能相同，不过我们很高兴，我们的神经网络的预测结果达到了93%，这是一个很不错的开端，我们还有可以提升精度的地方，比如说我们传递进去的是784个像素点，但是你知道这些像素点之间的联系比较少，所以从一开始就决定了我们的神经网络的精度不会太高，我们需要找到这些数字的一些特征用来训练，这样会比较好。但是我们的实验适可而止，我不会细究这些东西，如果你有兴趣的话，可以查找相关的论文，它们都有对这些数字的特征提取方法。

下一节我将贴出本节的代码。

[Prev]( ../chapter3/4.md) [Next]( 2.md )