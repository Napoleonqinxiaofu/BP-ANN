#MNISTtrain.py的代码

```bash
#MNISTtrain.py

import struct
import numpy
import cv2

import BPANN

def getDataFromFile(  imagePath, labelPath, samples = 1000, func=None ):
    """
        从MNIST数据集中获取数据，因为在新的MNIST数据集中，数据存放的方式是将每一个图片铺平之后序列存储到文件中的，所以我们可以反过来将其读取出来。
        inputs:
	        imagePath : 保存图片的文件
	        labelPath : 保存图像标签信息的文件
	        samples : 需要取得多少的图片，默认为1000张
	        func : 在获取每一张图片之前是否需要处理一下，比如细化，或者我们想获取的是图像的其他信息，可以由这个函数来处理
    """
    binaryImageData = open( imagePath, 'rb' )
    imageBuffer = binaryImageData.read()
    binaryImageData.close()
    
    binaryLabel = open( labelPath , 'rb' )
    labelBuffer = binaryLabel.read()
    binaryLabel.close()
    
    trainData = []
    resultData = []
    #使用大端法读取四个整型数---每个整型数4个字节，分别为魔数、图片数量、图片像素行列数，
    #index为位置指针。(魔数，图片类型的数)
    #不过我们不需要这些东西
    index = 0
    #magic, numImages, numRows, numColums=struct.unpack_from('>iiii', imageBuffer, index )
    
    index += struct.calcsize('>iiii' )
    
    for x in range(samples):
        img = numpy.array( struct.unpack_from( '>784B', imageBuffer, index ) )\
                    .reshape( 28, 28).astype( numpy.uint8 )
        #二值化图像
        img[numpy.where( img[:, :] > 0)] = 1
        
        if func is None:
            img = img.reshape( 784, -1 )
        else:
            img = func( img )

        trainData.append( img )
        index += struct.calcsize( '>784B' )
    
    #获得对应的标签
    index = struct.calcsize('>ii' )
    for x in range(samples):
        r = numpy.zeros( 10 ).reshape( 10, -1 )
        result = numpy.array( struct.unpack_from( '>B', labelBuffer, index ) )[0]
        r[result] = 1;
        resultData.append( r )
        index += struct.calcsize( '>B' )
        
    return zip( trainData, resultData )

    def imshow( img, nameOfWindow='nameOfWindow' ):
		cv2.imshow( nameOfWindow, img )
		cv2.waitKey(0)
		cv2.destroyAllWindows()

	
	"""
	将灰度图像转换成彩色图像，方便查看效果
	"""
	def cvt2BGR( img ):
		edges = cv2.cvtColor( img.copy(), cv2.COLOR_GRAY2BGR )
		return edges

	train = getDataFromFile( './samples/train-images.idx3-ubyte', './samples/	train-labels.idx1-ubyte', 60000 )
	if __name__ == '__main__':
		"""
	    for i in range( 10 ):
	        img = train[i][0].reshape( 28, 28 ).astype( numpy.uint8 ) * 255 
	        number = numpy.argmax( train[i][1] )
	        font = cv2.FONT_HERSHEY_SIMPLEX
	        img = cvt2BGR( img )
	        cv2.putText( img, str( number ), ( 0, 20 ), font, 1, ( 255, 0, 0 ), 1 )
	        imshow( img )
    	"""
    	# 初始化神经网络
	    net = BPANN.BPANN( [784, 30, 10 ] )
	    
	    # 训练，参数比较随意，所以结果不是最佳的
	    #30表示迭代次数
	    #6表示我们将训练的数据分成若干份，每一份包含6个数据
	    #0.2表示学习速率
	    net.SGD( train[:50000], 30, 6, 0.2, train[50000:] )
	    
	    # 保存网络的参数
	    net.save( 'netParam.txt' )
```

另外你可能很疑惑的一点就是我怎么就知道要将隐藏层的神经元的数量设置为30，学习速率设置为0.2的呢？老实说，我是跟着那个英文教程来设置这些参数的，但是我知道这不是最终的解决办法，所以后来我自己做了一些实验，得出一些比较，进而得出哪一个学习速率比较好，隐藏层的神经元的数目要多少比较合适。具体的实验方法就是，我让学习速率从0.1变化到10，变化的间隔为0.1，然后用我们写的神经网络来训练，最终保存这个学习速率之下的预测精度，对于隐藏层的神经数目也是一样的，我从10到500进行训练（但是我要提醒你一下，神经元的数量越多，运行起来越吃力，如果你有时间的话，自己去实践一下吧）。好了，我就不告诉你我观察到的最佳参数的组合是什么了，因为你自己就可以做到的事情，千万别问别人。


最后，我的教程也写完了，总的来说，自己现在觉得很晕，这篇教程还是比较烂的，我自己在写之前曾经想过应该怎么解释这些代码，解释这些公式，想想倒是挺简单的，但是真正用文字来表达的时候就有点儿捉襟见肘了，所以在解释的时候可能就会漏掉一些应该补充的知识，当局者迷。如果你觉得哪儿讲得不好，希望你能在issue中提到，我会尽量修改这篇教程的。我希望这篇教程能够帮助到你。

另外你可以在code文件夹下下载相关的代码。